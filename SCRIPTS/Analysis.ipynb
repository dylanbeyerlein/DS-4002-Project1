{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "88ec2f5d",
      "metadata": {
        "id": "88ec2f5d"
      },
      "source": [
        "The code below performs the following functions now that the data is cleaned\n",
        "\n",
        "1. FREQUENCY ANALYSIS:\n",
        "   - Reloads the cleaned datasets.\n",
        "   - Converts token strings back into Python lists.\n",
        "   - Extracts all tokens for each section.\n",
        "   - Computes word‑frequency counts using Counter.\n",
        "   - Prints the top 10 most frequent words for News and Opinion.\n",
        "\n",
        "2. EDA VISUALIZATION:\n",
        "   - Creates bar charts showing the top 10 most frequent words in each section.\n",
        "   - Helps visualize differences in vocabulary emphasis between News and Opinion titles.\n",
        "\n",
        "3. STATISTICAL COMPARISON:\n",
        "   - Identifies the 25 most common words across both sections.\n",
        "   - Builds a contingency table of News vs. Opinion word counts.\n",
        "   - Performs a chi‑square test of independence to evaluate whether\n",
        "     News and Opinion sections differ significantly in their word‑frequency distributions.\n",
        "   - Prints the chi‑square statistic, degrees of freedom, and p‑value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1da606a",
      "metadata": {
        "id": "c1da606a"
      },
      "outputs": [],
      "source": [
        "# Extract top 10 words for opinions and news\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from itertools import chain\n",
        "import ast  # safely converts string -> list\n",
        "\n",
        "news = pd.read_csv(r\"../DATA/News_cleaned.csv\")\n",
        "opinion = pd.read_csv(r\"../DATA/Opinion_cleaned.csv\")\n",
        "\n",
        "news['tokens'] = news['tokens'].apply(ast.literal_eval)\n",
        "opinion['tokens'] = opinion['tokens'].apply(ast.literal_eval)\n",
        "\n",
        "df = pd.concat([news, opinion], ignore_index=True)\n",
        "\n",
        "news_words = list(chain.from_iterable(df[df['section'] == 'News']['tokens']))\n",
        "opinion_words = list(chain.from_iterable(df[df['section'] == 'Opinion']['tokens']))\n",
        "\n",
        "news_freq = Counter(news_words)\n",
        "opinion_freq = Counter(opinion_words)\n",
        "\n",
        "print(\"Top 10 News words:\")\n",
        "print(news_freq.most_common(10))\n",
        "\n",
        "print(\"\\nTop 10 Opinion words:\")\n",
        "print(opinion_freq.most_common(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4921cea",
      "metadata": {
        "id": "f4921cea"
      },
      "outputs": [],
      "source": [
        "# Generate EDA Plots\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot 1: News\n",
        "words, counts = zip(*news_freq.most_common(10))\n",
        "plt.figure()\n",
        "plt.bar(words, counts)\n",
        "plt.title(\"Top 10 Most Frequent Words in News Article Titles\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.xlabel(\"Word\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save to OUTPUT folder\n",
        "plt.savefig(\"../OUTPUT/news_top10.png\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Plot 2: Opinion\n",
        "words, counts = zip(*opinion_freq.most_common(10))\n",
        "plt.figure()\n",
        "plt.bar(words, counts)\n",
        "plt.title(\"Top 10 Most Frequent Words in Opinion Article Titles\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.xlabel(\"Word\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save to OUTPUT folder\n",
        "plt.savefig(\"../OUTPUT/opinion_top10.png\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['title_length'] = df['tokens'].apply(len)\n",
        "\n",
        "news_lengths = df[df['section'] == 'News']['title_length']\n",
        "opinion_lengths = df[df['section'] == 'Opinion']['title_length']\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "plt.boxplot(\n",
        "    [news_lengths, opinion_lengths],\n",
        "    labels=['News', 'Opinion']\n",
        ")\n",
        "plt.title(\"Distribution of Title Lengths by Section\")\n",
        "plt.ylabel(\"Number of Words per Title\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "l_HtC_lfQHxg"
      },
      "id": "l_HtC_lfQHxg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6038f9f6",
      "metadata": {
        "id": "6038f9f6"
      },
      "outputs": [],
      "source": [
        "# Perform Analysis on Word Usage Differences\n",
        "import pandas as pd\n",
        "import ast\n",
        "from collections import Counter\n",
        "from itertools import chain\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "news = pd.read_csv(r\"../DATA/News_cleaned.csv\")\n",
        "opinion = pd.read_csv(r\"../DATA/Opinion_cleaned.csv\")\n",
        "\n",
        "news['tokens'] = news['tokens'].apply(ast.literal_eval)\n",
        "opinion['tokens'] = opinion['tokens'].apply(ast.literal_eval)\n",
        "\n",
        "news_words = list(chain.from_iterable(news['tokens']))\n",
        "opinion_words = list(chain.from_iterable(opinion['tokens']))\n",
        "\n",
        "news_freq = Counter(news_words)\n",
        "opinion_freq = Counter(opinion_words)\n",
        "\n",
        "combined_freq = news_freq + opinion_freq\n",
        "top_words = [word for word, _ in combined_freq.most_common(25)]\n",
        "\n",
        "table = []\n",
        "for word in top_words:\n",
        "    table.append([\n",
        "        news_freq.get(word, 0),\n",
        "        opinion_freq.get(word, 0)\n",
        "    ])\n",
        "\n",
        "contingency_df = pd.DataFrame(\n",
        "    table,\n",
        "    index=top_words,\n",
        "    columns=[\"News\", \"Opinion\"]\n",
        ")\n",
        "\n",
        "# Save the table to OUTPUT folder\n",
        "contingency_df.to_csv(\"../OUTPUT/word_frequency_table.csv\")\n",
        "print(\"Saved table to ../OUTPUT/word_frequency_table.csv\")\n",
        "\n",
        "# Chi-square test\n",
        "chi2, p, dof, expected = chi2_contingency(contingency_df)\n",
        "\n",
        "print(f\"Chi-square statistic: {chi2:.2f}\")\n",
        "print(f\"Degrees of freedom: {dof}\")\n",
        "print(f\"P-value: {p:.6f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "467232a4",
      "metadata": {
        "id": "467232a4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}